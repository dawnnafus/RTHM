---
title: "Linking Health Indicators to Refinery Emissions"
author: "Niklas Lollo"
output: 
  html_document:
    toc: true
---

```{r setup, include=FALSE, echo=F}
knitr::opts_chunk$set(echo = TRUE)
# List of R packages
required_pkg <- c("tidyverse","maptools", "rgdal", "spatstat", "ggmap", "geosphere", "leaflet", "spdep", "sp")
#pkgs_not_installed <- required_pkg[!sapply(required_pkg, function(p) require(p, character.only=T))]
#install.packages(pkgs_not_installed, dependencies=TRUE)

# Load all libraries at once.
lapply(required_pkg, library, character.only = TRUE) 
```

```{r time dataset, message=F, warning=F, echo=F}
# Inputs here are date_begin and date_end
begin = "2016-05-09 14:00"
end = "2016-08-11 0:00"

timeframe <- function(date_begin = begin, 
                      date_end = end){
  exp_begin = as.POSIXct(date_begin, tz="GMT", format="%Y-%m-%d %H")
  exp_end = as.POSIXct(date_end, tz="GMT", format="%Y-%m-%d %H")
  out = data_frame(day = seq(exp_begin, exp_end, by = 3600))
  return(out)
}
full_time <- timeframe()

exp_begin = as.POSIXct(begin, tz="GMT", format="%Y-%m-%d %H")
exp_end = as.POSIXct(end, tz="GMT", format="%Y-%m-%d %H")
```

```{r load air quality data, warning=F, message=F, echo=F}
# load air quality data
feed_4902 <- read_csv("../refinery_data/airQuality_feed4902_data.csv")
feed_4901 <- read_csv("../refinery_data/airQuality_feed4901_data.csv")
feed_4902_methane <- read_csv("../refinery_data/airQuality_N20_methane_4902_data.csv")

# Make hourly averages
## Set zero's to NA to not "mess up" average
feed_4902[feed_4902 == 0] <- NA
## Create new dataframe
hourly_4902 <- feed_4902 %>%
  # Select the day and hour of interest (get rid of minute and seconds)
  group_by(
    # Creates new variables
    day = as.POSIXct(cut(t, breaks='hour'))) %>%
  summarise(
    # Averages
    sulfur_dioxide = mean(sulfurDioxide, na.rm=T),
    carbon_monoxide = mean(carbonMonoxide, na.rm=T),
    ozone = mean(ozone, na.rm=T),
    pm_2.5 = mean(pm2_5, na.rm=T)
    ) %>%
  ungroup() %>%
  # Arrange the columns by day
  arrange(day) %>%
  full_join(full_time, by = "day")

# Do the same for the other feed 4902 dataframe
feed_4902_methane[feed_4902_methane == 0] <- NA
hourly_4902_methane <- feed_4902_methane %>%
    group_by(
    # Creates new variables
    day = as.POSIXct(cut(t, breaks='hour'))) %>%
  summarise(
    # Averages
    methane = mean(Methane, na.rm=T),
    benzene = mean(Benzene, na.rm=T),
    nitrous_oxide = mean(`Nitrous Oxide`, na.rm=T),
    xylene = mean(Xylene, na.rm=T)
    ) %>%
  # Arrange the columns by day
  arrange(day) %>%
  full_join(full_time, by = "day")

# Merge feed 4902 data
air_qual_4902 <- right_join(hourly_4902, hourly_4902_methane, by = "day") %>%
  mutate(id = "feed_4902")

# Do the same for feed 4901
feed_4901[feed_4901 == 0] <- NA
air_qual_4901 <- feed_4901 %>%
  # Select the day and hour of interest (get rid of minute and seconds)
  group_by(
    # Creates new variables
    day = as.POSIXct(cut(t, breaks='hour'))) %>%
    # Averages
  summarise(
    sulfur_dioxide = mean(sulfurDioxide, na.rm=T),
    carbon_monoxide = mean(carbonMonoxide, na.rm=T),
    ozone = mean(ozone, na.rm=T),
    pm_2.5 = mean(pm2_5, na.rm=T)
    ) %>%
  mutate(
    id = "feed_4901"
    ) %>%
  # Arrange the columns by day
  arrange(day) %>%
  full_join(full_time, by = "day")

# Remove intermediate dataframes
rm(hourly_4902, hourly_4902_methane)
# Remove original dataframes
rm(feed_4901, feed_4902, feed_4902_methane)
```

```{r create air quality dataset, message=F, warning=F, echo=F}
# Merge feeds
air_quality <- full_join(full_time, air_qual_4901, by = "day") %>%
  full_join(air_qual_4902, 
            by = c("day", "id", "sulfur_dioxide",
                   "carbon_monoxide", "ozone", "pm_2.5")) %>%
  select(day, id, everything()) %>%
  mutate(id = as.factor(id)) %>%
  arrange(day)

# Remove intermediate dataframes
rm(air_qual_4901, air_qual_4902)

# Collect refinery address from google
refinery = as.numeric(geocode("525 Castro St, Richmond, CA 94801", 
                              source = "google"))

# Add refinery coordinates to air quality
air_quality <- air_quality %>%
  mutate(
    longitude = refinery[1],
    latitude = refinery[2])
```

```{r exposure window, message=F, warning=F, echo=F}
# Moving window average of sulfur dioxide
air_quality <- 
  air_quality %>% 
  group_by(id) %>% 
  arrange(day) %>%
  mutate(
    sulfur_dioxide_exposure_window = 
      zoo::rollapply(sulfur_dioxide,
                     width = 8, #TO DO: Select number of hours to include
                     FUN = mean, #function is mean
                     na.rm = T, #avoids NA
                     partial = T, #skips unnecessary datapoints
                     align = "right")) %>%
  ungroup %>%
  arrange(id, day)
```

```{r load paco data, warning=F, message=F, echo=F}
# load paco data
paco <- read_csv("../refinery_data/paco_all.csv")

# Creating new dataframe
paco <- paco %>%
  mutate(
    # Remove extra values (supposed to be a correction)
    when=gsub("\\+0000","",when),
    # Converting / to - part 1
    when=sub("[[:punct:]]","-",when),
    # Converting / to - part 2
    when=sub("\\/","-",when),
    # Rename persons of interest
    who = replace(who, who=="meaningfrommonitoring3@gmail.com", "m3"),
    who = replace(who, who=="meaningfrommonitoring5@gmail.com", "m5"),
    who = replace(who, who=="meaningfrommonitoring7@gmail.com", "m7"),
    who = replace(who, who=="meaningfrommonitoring9@gmail.com", "m9"),
    who = replace(who, who=="meaningfrommonitoring10@gmail.com", "m10"),
    who = replace(who, who=="meaningfrommonitoring11@gmail.com", "m11"),
    who = replace(who, who=="meaningfrommonitoring16@gmail.com", "m16")
  ) %>%
  mutate(
    # Make person column as a factor
    id = as.factor(who),
    # Convert date column to datetime
    t = as.POSIXct(when, tz="GMT", format="%Y-%m-%d %H:%M:%S")) %>%
  # Remove columns not of interest
  select(-c(who, when, appId, pacoVersion, experimentId,
            experimentName, experimentVersion, experimentGroupName,
            actionTriggerId, actionId, actionSpecId, responseTime,
            scheduledTime, timeZone)) %>%
  # Select persons of interest 
  filter(id == "m3" | id == "m5" | id == "m7" |
      id == "m9" | id == "m10" | id == "m11" |
      id == "m16") %>%
  arrange(t)

# Remove unlikely values
paco$SPO2[paco$SPO2 > 100 | paco$SPO2 < 80] <- NA

# Make hourly dataframe
paco_hourly <- paco %>%
  # Select the person, day and hour of interest
  group_by(id,
    # Creates new variables
    day = as.POSIXct(cut(t, breaks='hour'))) %>%
  # Average
  summarise(
    blood_oxygen = mean(SPO2, na.rm=T),
    symptoms = first(Symptoms),
    doctor = first(doctor),
    medicine = first(medicine),
    text_entry = first(`Participant choice`)
    ) %>%
  filter(is.na(blood_oxygen) == F) %>% 
  complete(nesting(id), 
           day = seq(exp_begin, exp_end, by = 3600),  
           #completing all levels of id:day
           fill = list(blood_oxygen = NA)) %>%
  ungroup %>%
  # Select persons of interest 
  filter(id == "m3" | id == "m5" | id == "m7" |
      id == "m9" | id == "m10" | id == "m11" |
      id == "m16") %>%
  # Arrange the columns by person
  arrange(id)

# Remove original dataframe
rm(paco)
```

```{r load fitbit data, message=F, warning=F, echo=F}
# Load intraday activity
fb_intraday_m3 <- read_csv("../refinery_data/fitbit_intradayactivities_m3.csv") %>%
  mutate(id = "m3")
fb_intraday_m5 <- read_csv("../refinery_data/fitbit_intradayactivities_m5.csv")%>%
  mutate(id = "m5")
fb_intraday_m7 <- read_csv("../refinery_data/fitbit_intradayactivities_m7.csv")%>%
  mutate(id = "m7")
fb_intraday_m9 <- read_csv("../refinery_data/fitbit_intradayactivities_m9.csv")%>%
  mutate(id = "m9")
fb_intraday_m11 <- read_csv("../refinery_data/fitbit_intradayactivities_m11.csv")%>%
  mutate(id = "m11")
fb_intraday_m16 <- read_csv("../refinery_data/fitbit_intradayactivities_m16.csv")%>%
  mutate(id = "m16")

# Combine dataframes
fb_intra <- bind_rows(fb_intraday_m3, fb_intraday_m5, .id = NULL) %>%
  bind_rows(fb_intraday_m7, .id = NULL) %>%
  bind_rows(fb_intraday_m9, .id = NULL) %>%
  bind_rows(fb_intraday_m11, .id = NULL) %>%
  bind_rows(fb_intraday_m16, .id = NULL) %>%
  mutate(id = as.factor(id))

# Remove intermediate dataframes
rm(fb_intraday_m3, fb_intraday_m5, fb_intraday_m7,
   fb_intraday_m9, fb_intraday_m11, fb_intraday_m16)

# Make hourly data
fb_intraday <- fb_intra %>% 
  group_by(id,
    # Creates new variables
    day = as.POSIXct(cut(t, breaks='hour'))) %>%
  summarise(
    # Averages
    calories = sum(calories, na.rm=T),
    distance = sum(distance, na.rm=T),
    steps = sum(steps, na.rm=T),
    heart_rate = mean(heart, na.rm=T),
    floors = sum(floors, na.rm=T),
    elevation = sum(elevation, na.rm=T)) %>%
    complete(nesting(id),
             day = seq(exp_begin, exp_end, by = 3600),
             #completing all levels of id:day
             fill = list(calories = NA,distance = NA,
                         steps = NA, heart_rate = NA,
                         floors = NA, elevation = NA)) %>%
  # Select persons of interest 
  filter(id == "m3" | id == "m5" | id == "m7" |
      id == "m9" | id == "m10" | id == "m11" |
      id == "m16") %>%
  # Arrange the columns by day
  arrange(id, day) 

# Remove original dataframes
rm(fb_intra)
```

```{r make individual data, message=F, warning=F, echo=F}
# Collect participant home addresses
m3_home = as.numeric(
  geocode("460 3rd St, Richmond, CA 94801",
          source="google"))
m5_home = as.numeric(
  geocode("2515 Downer Ave, Richmond, CA 94804",
          source="google"))
m7_home = as.numeric(
  geocode("2640 Esmond Ave, Richmond, CA 94804",
          source="google"))
m9_home = as.numeric(
  geocode("1612 Mission Ave, San Pablo, CA 94806",
          source="google"))
m10_home = as.numeric(
  geocode("1832 4th St, Richmond, CA 94801",
          source="google"))
m11_home = as.numeric(
  geocode("2836 18th St, San Pablo, CA 94806",
          source="google"))
m16_home = as.numeric(
  geocode("5733 Oakmont Dr, Richmond, CA 94806",
          source="google"))

# Make demographics dataframe
# Will load in later
demographics <- data_frame(
  id =  c("m3","m5","m7","m9","m10","m11","m16"),
  age = c(21,34,45,33,56,67,51),
  time_in_area = c(20,16,5,10,50,32,27),
  home_lat = c(m3_home[2], m5_home[2], m7_home[2],
               m9_home[2], m10_home[2], m11_home[2], m16_home[2]),
  home_long = c(m3_home[1], m5_home[1], m7_home[1],
                m9_home[1], m10_home[1], m11_home[1], m16_home[1]),
  sex = as.factor(c("male","female","male","female","female","male","female"))) %>%
  mutate(
    home_dist_to_refinery = distm(cbind(home_long, home_lat), 
                                  refinery, 
                                  fun= distHaversine))

# LongLat randomizer
# Will have real GPS data loaded 
set.seed(0)
long_possible = (-12243009:-12153414)/100000
lat_possible = (3771863:3809988)/100000
longitude = sample(long_possible,24414, replace = T)
latitude = sample(lat_possible,24414, replace = T)

# Merge demographics with fitbit and paco datasets
fb_data <- left_join(fb_intraday, demographics, by = "id") %>%
  ungroup %>%
  mutate(id = as.factor(id))
paco_data <- full_join(paco_hourly, demographics, by = "id") %>%
  ungroup %>%
  mutate(id = as.factor(id))

# Combine all individual data
individual_data <- fb_data %>%
  bind_rows(paco_data, .id = NULL) %>%
  filter((heart_rate > 30 & heart_rate < 200) | is.na(heart_rate)) %>%
  mutate(
    longitude = sample(longitude, replace = T),
    latitude = sample(latitude, replace = T))

# Remove old dataframes
rm(paco_hourly, fb_intraday, paco_data, fb_data)
```

```{r TO DO filter your data, message=F, warning=F, echo=F}
# Merged dataframe 
total_df <- individual_data %>%
  #filter(sex == "male" & age > 50) %>% # TO DO: select demographic filters
  bind_rows(air_quality, .id = NULL) %>%
  mutate(id = as.factor(id))

# Intermediate dataframe - remove pollution variables
binding_df <- total_df %>%
  select(-c(methane, sulfur_dioxide, ozone,
            benzene, pm_2.5, carbon_monoxide,
            sulfur_dioxide_exposure_window, xylene,
            nitrous_oxide))

# To be used in spatial analysis
spatial_df <- total_df %>%
  group_by(day) %>%
  summarize(
    methane = mean(methane, na.rm=T),
    sulfur_dioxide = mean(sulfur_dioxide_exposure_window, na.rm=T),
    ozone = mean(ozone, na.rm=T),
    benzene = mean(benzene, na.rm=T),
    pm_2.5 = mean(pm_2.5, na.rm=T),
    carbon_monoxide = mean(carbon_monoxide, na.rm=T),
    so2_not_window = mean(sulfur_dioxide, na.rm=T),
    xylene = mean(xylene, na.rm=T),
    nitrous_oxide = mean(nitrous_oxide, na.rm=T)
  ) %>%
  ungroup %>%
  right_join(binding_df, by = "day") %>%
  filter(!is.na(id)) %>%
  arrange(day)

# Remove intermediate dataframe
rm(binding_df)

# Create data_frame for standard analysis
summary_df <- total_df %>%
  group_by(day) %>%
  summarize(
    # Pollutants
    methane = mean(methane, na.rm=T),
    sulfur_dioxide = mean(sulfur_dioxide_exposure_window, na.rm=T),
    ozone = mean(ozone, na.rm=T),
    benzene = mean(benzene, na.rm=T),
    pm_2.5 = mean(pm_2.5, na.rm=T),
    carbon_monoxide = mean(carbon_monoxide, na.rm=T),
    so2_not_window = mean(sulfur_dioxide, na.rm=T),
    xylene = mean(xylene, na.rm=T),
    nitrous_oxide = mean(nitrous_oxide, na.rm=T),
    # Health indicators
    heart_rate = mean(heart_rate, na.rm=T),
    blood_oxygen = mean(blood_oxygen, na.rm=T),
    # Summary demographics
    time_in_area = mean(time_in_area, na.rm=T),
    age = mean(age, na.rm=T),
    home_dist_to_refinery = mean(home_dist_to_refinery, na.rm=T),
    symptoms = mean(symptoms, na.rm=T),
    text_entry = first(text_entry)
    ) %>%
  ungroup
```

## Filters
This analysis looks at 

```{r plot theme, warning=F, message=F, echo=F}
# Create plotting theme
theme_fair_tech <- theme(
  legend.position = "bottom",
  panel.background = element_rect(fill = NA),
  # panel.border = element_rect(fill = NA, color = "grey75"),
  axis.ticks = element_line(color = "grey95", size = 0.3),
  panel.grid.major = element_line(color = "grey95", size = 0.3),
  panel.grid.minor = element_line(color = "grey95", size = 0.3),
  legend.key = element_blank(),
  plot.title = element_text(size=20, face="bold", color = "maroon", 
    margin = margin(10, 0, 10, 0))
  )
```

# Correlations

## Plots^[For help on interpreting a correlation plot, visit this [page](https://www.mathsisfun.com/data/images/correlation-examples.svg)]

t-tests for Statistical Significance^[Welch two-sample t-test]

These tests compare the difference between the population mean health outcome (e.g. heart rate) and the mean health outcome when the environmental input (e.g. methane) is above its median value. Actually does not do this anymore.

+ To do: should make this analysis (maybe also) look at when pollutant is above permitted limit or if it is present at all.

```{r make plot function, warning=F, message=F, echo=F}
my_plot <- function(df = summary_df,
                    health_var,
                    health_var_name,
                    health_var_units,
                    pollutant_var,
                    pollutant_var_name, 
                    pollutant_var_units){
  
  health_var <- enquo(health_var)
  pollutant_var <- enquo(pollutant_var)

  # Correlation
  df %>%
    filter(!is.na(!!health_var) & !is.na(!!pollutant_var)) %>%
    select(UQ(health_var), UQ(pollutant_var)) %>% 
    boot::corr() %>% # why not use cor()?
    round(3) -> correlation

  # t-test
  df %>% 
    filter(!is.na(!!health_var)) %>%
    transmute(health = !!health_var) -> health
  
  df %>%
    filter(!is.na(!!health_var) & !is.na(!!pollutant_var)) %>%
    # Not filtering for above median anymore
    select(UQ(health_var)) -> sample

  # Perhaps should compare to air_quality standards instead of median
  t_test <- t.test(x = sample[[1]], y = health[[1]])

  df %>%
    filter(!is.na(!!health_var) & !is.na(!!pollutant_var)) %>%
    transmute(
      health = !!health_var,
      pollutant = !!pollutant_var) -> df_new

    # Plot
  df_new %>%
    ggplot() + 
      geom_point(aes(x= health, y= pollutant)) +
      geom_smooth(aes(x= health, y= pollutant), 
                  method = "lm", se=F) +
      scale_x_continuous() +
      scale_y_continuous() +
      theme_fair_tech + 
      labs(x=paste0(health_var_name,
                    " (",health_var_units,")"), 
           y=paste0(pollutant_var_name,
                    " (",pollutant_var_units,")")) +
      ggtitle(paste0(health_var_name, 
                     " & ", pollutant_var_name),
              subtitle=paste0("r = ", correlation,
                              ", p-value = ",
                              round(t_test$p.value,4)))
}
```

```{r run plots, warning=F, message=F, echo=F}
# Blood Oxygen and Sulfur Dioxide
my_plot(health_var = blood_oxygen,
        health_var_name = "Blood Oxygen",
        health_var_units = "%",
        pollutant_var = sulfur_dioxide,
        pollutant_var_name = "Sulfur Dioxide",
        pollutant_var_units = "ppb")

# Heart Rate and Sulfur Dioxide
my_plot(health_var = heart_rate,
        health_var_name = "Heart Rate",
        health_var_units = "bpm",
        pollutant_var = sulfur_dioxide,
        pollutant_var_name = "Sulfur Dioxide",
        pollutant_var_units = "ppb")

# Heart Rate and Methane
my_plot(health_var = heart_rate,
        health_var_name = "Heart Rate",
        health_var_units = "bpm",
        pollutant_var = methane,
        pollutant_var_name = "Methane",
        pollutant_var_units = "ppb")
```

# Spatial Analysis

## Plot points
```{r plot spatial points, echo=F, message=F, warning=F}
# Load contra costa county shapefile
cc <- readOGR(dsn ="../refinery_data/location/BaseMapGrid", 
              layer = "GRD_PWD_BaseMap_0106",
              verbose = F)

# Convert to longlat data
cc_wgs84 <- spTransform(cc, 
                        CRS("+proj=longlat +datum=WGS84"))


# Basic plot of contra costa county
r <- ggplot(cc_wgs84, aes(x=long, y=lat)) + 
  geom_path(aes(group=group)) + 
  coord_map("mercator") + 
  geom_point(aes(x= refinery[1], y= refinery[2])) 

# Plot ids on contra costa county map
r + 
  geom_point(data=spatial_df, 
             aes(x=longitude, y=latitude, 
                 color = id), 
             na.rm = T) 

# Plot heart rate over space
r + 
  geom_point(data=spatial_df, 
             aes(x=longitude, y=latitude,
                 color = heart_rate), 
             na.rm = T)
```

## Autocorrelation
```{r spatial autocorrelation, echo=F, warning=F, message=F}
### Dtermine which points are near
# Select only the spatial points
points <- spatial_df %>% select(longitude, latitude)

# Turn into spatial dataframe
spat_points <- SpatialPoints(points,
                             proj4string = CRS("+proj=longlat +datum=WGS84"))

# Nearest neighbor assignment
points_nb <- dnearneigh(spat_points, d1 = 0, d2 = .1)

# Convert into weights
spatial_weights <- nb2mat(points_nb, zero.policy = T)

# Convert into listw
spatial_listw <- nb2listw(points_nb, zero.policy =T)

# Intermediate dataframe removing LatLong
spatial_df_t <- spatial_df %>% select(-c(longitude, latitude))

# Make spatial points dataframe with merge
spatial_points <- SpatialPointsDataFrame(coords = points,
                            data = spatial_df_t,
                            proj4string = 
                              CRS("+proj=longlat +datum=WGS84"),
                            match.ID = T)

# Moran's I Monte Carlo
moran_out <- moran.mc(spatial_df$heart_rate,
                      spatial_listw,
                      nsim=99,
                      zero.policy = T,
                      na.action = na.omit)

paste0("Moran's I p-value: ", moran_out$p.value)
paste0("Moran's I z-score: ", moran_out$statistic)
```

## Load Cal Enviro Screen
```{r Cal Enviro Screen, warning=F, echo=F, message=F}
## Load community health assessment data
ces <- readOGR(dsn ="../refinery_data/location/CES3Results", 
               layer = "CES3Results")

# Spatial transform
ces_lat <- spTransform(ces, CRS("+proj=longlat +datum=WGS84"))

# Subset for Contra Costa County
ces_lat_cc <- subset(ces_lat, County == "Contra Costa")
head(ces_lat_cc@data) # Examine the data of interest

# Add a new column "id" from the rownames
ces_lat_cc@data$id <- rownames(ces_lat_cc@data)

# Create a dataframe from the spatial object
new_data <- fortify(ces_lat_cc, region = "id")

# Merge the "fortified" data with the spatial object data
waterDF <- merge(new_data, ces_lat_cc@data, by = "id")

# Map (e.g. the cardiovascular scores)
ggplot(waterDF, aes(x=long, 
                    y=lat, 
                    group = group, 
                    fill = Cardiovasc)) +
  geom_polygon()  +
  geom_path(color = "white") +
  scale_fill_gradient(
    low = "plum1", high = "purple4",
    breaks=c(500000,1000000,1500000),
    labels=c("Low","Medium","High")) +
  coord_map("mercator") + 
  ggtitle("Cardiovascular Health")
```
