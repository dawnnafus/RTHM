---
title: "Linking Health Indicators to Refinery Emissions"
author: "Niklas Lollo"
output: 
  html_document:
    toc: true
---

```{r setup, include=FALSE, echo=F}
# http://rmarkdown.rstudio.com/index.html
knitr::opts_chunk$set(echo = TRUE)
# List of R packages
required_pkg <- c("tidyverse","maptools", "rgdal", "spatstat", "ggmap", "geosphere", "leaflet", "spdep", "sp")
#pkgs_not_installed <- required_pkg[!sapply(required_pkg, function(p) require(p, character.only=T))]
#install.packages(pkgs_not_installed, dependencies=TRUE)

# Load all libraries at once.
lapply(required_pkg, library, character.only = TRUE) 
```

```{r time dataset, message=F, warning=F, echo=F}
# Inputs here are date_begin and date_end
timeframe <- function(date_begin = "2016-05-09 14:00", 
                      date_end = "2016-08-11 0:00"){
  exp_begin = as.POSIXct(date_begin, tz="GMT", format="%Y-%m-%d %H")
  exp_end = as.POSIXct(date_end, tz="GMT", format="%Y-%m-%d %H")
  out = data_frame(day = seq(exp_begin, exp_end, by = 3600))
  return(out)
}
full_time <- timeframe()

# Manual
date_begin = "2016-05-09 14:00"
date_end = "2016-08-11 0:00"
exp_begin = as.POSIXct(date_begin, tz="GMT", format="%Y-%m-%d %H")
exp_end = as.POSIXct(date_end, tz="GMT", format="%Y-%m-%d %H")
```

```{r load air quality data, warning=F, message=F, echo=F}
# load air quality data
feed_4902 <- read_csv("../refinery_data/airQuality_feed4902_data.csv")
feed_4901 <- read_csv("../refinery_data/airQuality_feed4901_data.csv")
feed_4902_methane <- read_csv("../refinery_data/airQuality_N20_methane_4902_data.csv")

# Make hourly averages
## Set zero's to NA to not "mess up" average
feed_4902[feed_4902 == 0] <- NA
## Create new dataframe
hourly_4902 <- feed_4902 %>%
  # Select the day and hour of interest (get rid of minute and seconds)
  group_by(
    # Creates new variables
    day = as.POSIXct(cut(t, breaks='hour'))) %>%
  summarise(
    # Averages
    sulfur_dioxide = mean(sulfurDioxide, na.rm=T),
    carbon_monoxide = mean(carbonMonoxide, na.rm=T),
    ozone = mean(ozone, na.rm=T)) %>%
  ungroup() %>%
  # Arrange the columns by day
  arrange(day) %>%
  full_join(full_time, by = "day")

# Do the same for the other feed4902 dataframe
feed_4902_methane[feed_4902_methane == 0] <- NA
hourly_4902_methane <- feed_4902_methane %>%
    group_by(
    # Creates new variables
    day = as.POSIXct(cut(t, breaks='hour'))) %>%
  summarise(
    # Averages
    methane = mean(Methane, na.rm=T),
    benzene = mean(Benzene, na.rm=T),
    nitrous_oxide = mean(`Nitrous Oxide`, na.rm=T)) %>%
  # Arrange the columns by day
  arrange(day) %>%
  full_join(full_time, by = "day")

air_qual_4902 <- right_join(hourly_4902, hourly_4902_methane, by = "day") %>%
  mutate(id = "feed_4902")

# Do the same for feed 4901
feed_4901[feed_4901 == 0] <- NA
air_qual_4901 <- feed_4901 %>%
  # Select the day and hour of interest (get rid of minute and seconds)
  group_by(
    # Creates new variables
    day = as.POSIXct(cut(t, breaks='hour'))) %>%
    # Averages
  summarise(
    sulfur_dioxide = mean(sulfurDioxide, na.rm=T),
    carbon_monoxide = mean(carbonMonoxide, na.rm=T),
    ozone = mean(ozone, na.rm=T)) %>%
  mutate(
    id = "feed_4901"
  ) %>%
  # Arrange the columns by day
  arrange(day) %>%
  full_join(full_time, by = "day")

# Remove intermediate dataframes
rm(hourly_4902, hourly_4902_methane)
# Remove original dataframes
rm(feed_4901, feed_4902,feed_4902_methane)
```

```{r create air quality dataset, message=F, warning=F, echo=F}
# Air Quality data
air_quality <- full_join(full_time, air_qual_4901, by = "day") %>%
  full_join(air_qual_4902, 
            by = c("day", "id", "sulfur_dioxide",
                   "carbon_monoxide", "ozone")) %>%
  select(day, id, everything()) %>%
  mutate(id = as.factor(id)) %>%
  arrange(day)

rm(air_qual_4901, air_qual_4902)
```

```{r moving window, message=F, warning=F, echo=F}
# Moving window average of sulfur dioxide
air_quality <- 
  air_quality %>% 
  group_by(id) %>% 
  arrange(day) %>%
  mutate(
    sulfur_dioxide_exposure_window = 
      zoo::rollapply(sulfur_dioxide,
                     width = 8, #TO DO: Select number of hours to include
                     FUN = mean, #function is mean
                     na.rm = T, #avoids NA
                     partial = T, #skips unnecessary datapoints
                     align = "right")) %>%
  ungroup %>%
  arrange(id, day)
```

```{r load paco data, warning=F, message=F, echo=F}
# load paco data
paco <- read_csv("../refinery_data/paco_all.csv")

# Creating new dataframe
paco <- paco %>%
  mutate(
    # Remove extra values (supposed to be a correction)
    when=gsub("\\+0000","",when),
    # Converting / to - part 1
    when=sub("[[:punct:]]","-",when),
    # Converting / to - part 2
    when=sub("\\/","-",when),
    # Rename persons of interest
    who = replace(who, who=="meaningfrommonitoring3@gmail.com", "m3"),
    who = replace(who, who=="meaningfrommonitoring5@gmail.com", "m5"),
    who = replace(who, who=="meaningfrommonitoring7@gmail.com", "m7"),
    who = replace(who, who=="meaningfrommonitoring9@gmail.com", "m9"),
    who = replace(who, who=="meaningfrommonitoring10@gmail.com", "m10"),
    who = replace(who, who=="meaningfrommonitoring11@gmail.com", "m11"),
    who = replace(who, who=="meaningfrommonitoring16@gmail.com", "m16")
  ) %>%
  mutate(
    # Make person column as a factor
    id = as.factor(who),
    # Convert date column to datetime
    t = as.POSIXct(when, tz="GMT", format="%Y-%m-%d %H:%M:%S")) %>%
  # Remove columns not of interest
  select(-c(who, when, appId, pacoVersion, experimentId,
            experimentName, experimentVersion, experimentGroupName,
            actionTriggerId, actionId, actionSpecId, responseTime,
            scheduledTime, timeZone)) %>%
  # Select persons of interest 
  filter(id == "m3" | id == "m5" | id == "m7" |
      id == "m9" | id == "m10" | id == "m11" |
      id == "m16") %>%
  arrange(t)

# Remove incorrect values
paco$SPO2[paco$SPO2 == 0 | paco$SPO2 > 100 | paco$SPO2 < 80] <- NA
# Make hourly dataframe
paco_hourly <- paco %>%
  # Select the person, day and hour of interest
  group_by(id,
    # Creates new variables
    day = as.POSIXct(cut(t, breaks='hour'))) %>%
  # Average
  summarise(blood_oxygen = mean(SPO2, na.rm=T)) %>%
  filter(is.na(blood_oxygen) == F) %>% 
  complete(expand(nesting(id), day = seq(exp_begin, exp_end, by = 3600)),  
           #completing all levels of id:day
              fill = list(blood_oxygen = NA)) %>%
  # Select persons of interest 
  filter(id == "m3" | id == "m5" | id == "m7" |
      id == "m9" | id == "m10" | id == "m11" |
      id == "m16") %>%
  # Arrange the columns by person
  arrange(id)

rm(paco)
```

```{r load fitbit data, message=F, warning=F, echo=F}
# Load fitbit data
fb_body <- read_csv("../refinery_data/fitbit_body_data.csv")
fb_activities <- read_csv("../refinery_data/fitbit_activities_data.csv")
fb_sleep <- read_csv("../refinery_data/fitbit_sleep_data.csv")

# Merge daily fitbit data
fb_daily <- inner_join(fb_body, fb_activities, fb_sleep, by = "t")
rm(fb_body, fb_activities, fb_sleep)

# Load intraday activity
fb_intraday_m3 <- read_csv("../refinery_data/fitbit_intradayactivities_m3.csv") %>%
  mutate(id = "m3")
fb_intraday_m5 <- read_csv("../refinery_data/fitbit_intradayactivities_m5.csv")%>%
  mutate(id = "m5")
fb_intraday_m7 <- read_csv("../refinery_data/fitbit_intradayactivities_m7.csv")%>%
  mutate(id = "m7")
fb_intraday_m9 <- read_csv("../refinery_data/fitbit_intradayactivities_m9.csv")%>%
  mutate(id = "m9")
fb_intraday_m11 <- read_csv("../refinery_data/fitbit_intradayactivities_m11.csv")%>%
  mutate(id = "m11")
fb_intraday_m16 <- read_csv("../refinery_data/fitbit_intradayactivities_m16.csv")%>%
  mutate(id = "m16")

# Combine dataframes
fb_intra <- bind_rows(fb_intraday_m3, fb_intraday_m5, .id = NULL) %>%
  bind_rows(fb_intraday_m7, .id = NULL) %>%
  bind_rows(fb_intraday_m9, .id = NULL) %>%
  bind_rows(fb_intraday_m11, .id = NULL) %>%
  bind_rows(fb_intraday_m16, .id = NULL) %>%
  mutate(id = as.factor(id))

# Remove intermediate columns
rm(fb_intraday_m3, fb_intraday_m5, fb_intraday_m7,
   fb_intraday_m9, fb_intraday_m11, fb_intraday_m16)

# Make hourly data
fb_intraday <- fb_intra %>% 
  group_by(id,
    # Creates new variables
    day = as.POSIXct(cut(t, breaks='hour'))) %>%
  summarise(
    # Averages
    calories = sum(calories, na.rm=T),
    distance = sum(distance, na.rm=T),
    steps = sum(steps, na.rm=T),
    heart_rate = mean(heart, na.rm=T),
    floors = sum(floors, na.rm=T),
    elevation = sum(elevation, na.rm=T)) %>%
    complete(expand(nesting(id), day = seq(exp_begin, exp_end, by = 3600)),  
         #completing all levels of id:day
              fill = list(calories = NA,distance = NA,
                          steps = NA, heart_rate = NA,
                          floors = NA, elevation = NA)) %>%
  # Select persons of interest 
  filter(id == "m3" | id == "m5" | id == "m7" |
      id == "m9" | id == "m10" | id == "m11" |
      id == "m16") %>%
  # Arrange the columns by day
  arrange(id, day) 

# Remove original dataframes
rm(fb_intra, fb_daily)
```

```{r make individual data, message=F, warning=F, echo=F}
# Refinery address
refinery = as.numeric(geocode("525 Castro St, Richmond, CA 94801", 
                              source = "google"))

# Collect addresses
m3_locale = as.numeric(
  geocode("460 3rd St, Richmond, CA 94801",
          source="google"))
m5_locale = as.numeric(
  geocode("2515 Downer Ave, Richmond, CA 94804",
          source="google"))
m7_locale = as.numeric(
  geocode("2640 Esmond Ave, Richmond, CA 94804",
          source="google"))
m9_locale = as.numeric(
  geocode("1612 Mission Ave, San Pablo, CA 94806",
          source="google"))
m10_locale = as.numeric(
  geocode("1832 4th St, Richmond, CA 94801",
          source="google"))
m11_locale = as.numeric(
  geocode("2836 18th St, San Pablo, CA 94806",
          source="google"))
m16_locale = as.numeric(
  geocode("5733 Oakmont Dr, Richmond, CA 94806",
          source="google"))

# Make demographics dataframe
demographics <- data_frame(
  id =  c("m3","m5","m7","m9","m10","m11","m16"),
  age = c(21,34,45,33,56,67,51),
  home_lat = c(m3_locale[2], m5_locale[2], m7_locale[2], 
          m9_locale[2], m10_locale[2], m11_locale[2], m16_locale[2]),
  home_long = c(m3_locale[1], m5_locale[1], m7_locale[1], 
           m9_locale[1], m10_locale[1], m11_locale[1], m16_locale[1]),
  sex = as.factor(c("male","female","male","female","female","male","female"))) %>%
  mutate(
    home_dist_to_refinery = distm(cbind(home_long, home_lat), refinery, 
                                  fun= distHaversine))

# LongLat randomizer
set.seed(0)
long_possible = (-12243009:-12153414)/100000
lat_possible = (3771863:3809988)/100000
longitude = sample(long_possible,24427, replace = T)
latitude = sample(lat_possible,24427, replace = T)

# Merge with fb_intraday
fb_data <- left_join(fb_intraday, demographics, by = "id") %>%
  ungroup %>%
  mutate(
    id = as.factor(id)
  )
paco_data <- full_join(paco_hourly, demographics, by = "id") %>%
  ungroup %>%
  mutate(
    id = as.factor(id)
    )

# Individual data
individual_data <- fb_data %>%
  bind_rows(paco_data, .id = NULL) %>%
  filter((heart_rate > 30 & heart_rate < 200) | is.na(heart_rate)) %>%
  mutate(
    longitude = sample(longitude, replace = T),
    latitude = sample(latitude, replace = T)
  )

# Remove unnecessary dataframes
rm(paco_hourly, fb_intraday, paco_data, fb_data)
```

```{r TO DO filter your data, message=F, warning=F, echo=F}
# Add coordinates to air quality
air_quality <- air_quality %>%
  mutate(
    longitude = refinery[1],
    latitude = refinery[2]
  )

# Merged dataframe 
total_df <- individual_data %>%
  #filter(sex == "male" & age > 50) %>% # TO DO: select demographic filters
  bind_rows(air_quality, .id = NULL) %>%
  mutate(id = as.factor(id))

binding_df <- total_df %>%
  select(-c(methane, sulfur_dioxide)) # intermediate dataframe

# To be used in spatial analysis
spatial_df <- total_df %>%
  group_by(day) %>%
  summarize(
    methane = mean(methane, na.rm=T),
    sulfur_dioxide = mean(sulfur_dioxide_exposure_window, na.rm=T)
  ) %>%
  ungroup %>%
  right_join(binding_df, by = "day") %>%
  filter(!is.na(id)) %>%
  arrange(day)

rm(binding_df)

# Create data_frame for basic analysis
summary_df <- total_df %>%
  group_by(day) %>%
  summarize(
    # Pollutants
    methane = mean(methane, na.rm=T),
    sulfur_dioxide = mean(sulfur_dioxide_exposure_window, na.rm=T),
    # Health indicators
    heart_rate = mean(heart_rate, na.rm=T),
    blood_oxygen = mean(blood_oxygen, na.rm=T)
    ) %>%
  ungroup
```

## Filters
This analysis looks at: ___

```{r plot theme, warning=F, message=F, echo=F}
# http://zevross.com/blog/2014/08/04/beautiful-plotting-in-r-a-ggplot2-cheatsheet-3/#add-text-annotation-in-the-top-right-top-left-etc.-annotation_custom-and-friends

# Create ggplot theme
theme_fair_tech <- theme(
  legend.position = "bottom",
  panel.background = element_rect(fill = NA),
  # panel.border = element_rect(fill = NA, color = "grey75"),
  axis.ticks = element_line(color = "grey95", size = 0.3),
  panel.grid.major = element_line(color = "grey95", size = 0.3),
  panel.grid.minor = element_line(color = "grey95", size = 0.3),
  legend.key = element_blank(),
  plot.title = element_text(size=20, face="bold", color = "maroon", 
    margin = margin(10, 0, 10, 0))
  )
```

# Notes on Data Sources
Methane and sulfur dioxide readings collected in real-time by [Fenceline.org](fenceline.org)

Heart rate collected with Fitbit health monitors.

Blood Oxygen levels recorded with a pulse oximeter^[[Pulse Oximetry wiki](https://en.wikipedia.org/wiki/Pulse_oximetry)]

# Correlations

## Plots^[For help on interpreting a correlation plot, visit this [page](https://www.mathsisfun.com/data/images/correlation-examples.svg)]

t-tests for Statistical Significance^[Welch two-sample t-test]

These tests compare the difference between the population mean health outcome (e.g. heart rate) and the mean health outcome when the environmental input (e.g. methane) is above its median value.
```{r make plot function, warning=F, message=F, echo=F}
my_plot <- function(df = summary_df,
                    health_var,
                    health_var_name,
                    health_var_units,
                    pollutant_var,
                    pollutant_var_name, 
                    pollutant_var_units){
  health_var <- enquo(health_var)
  pollutant_var <- enquo(pollutant_var)

  # Correlation
  df %>%
    filter(!is.na(!!health_var) & !is.na(!!pollutant_var)) %>%
    select(UQ(health_var), UQ(pollutant_var)) %>% 
    boot::corr() %>% # why not use cor()?
    round(3) -> correlation

  # t-test
  df %>% 
    filter(!is.na(!!health_var)) %>%
    transmute(health = !!health_var) -> health
  
  df %>%
    filter(!is.na(!!health_var) & !is.na(!!pollutant_var)) %>%
    # Not filtering for above meadian anymore
    select(UQ(health_var)) -> sample

  # Perhaps should compare to air_quality standards instead of median
  t_test <- t.test(x = sample[[1]], y = health[[1]])

  df %>%
    filter(!is.na(!!health_var) & !is.na(!!pollutant_var)) %>%
    transmute(
      health = !!health_var,
      pollutant = !!pollutant_var) -> df_new

    # Plot
  df_new %>%
    ggplot() + 
      geom_point(aes(x= health, y= pollutant)) +
      geom_smooth(aes(x= health, y= pollutant), 
                  method = "lm", se=F) +
      scale_x_continuous() +
      scale_y_continuous() +
      theme_fair_tech + 
      labs(x=paste0(health_var_name," (",health_var_units,")"), 
           y=paste0(pollutant_var_name," (",pollutant_var_units,")")) +
      ggtitle(paste0(health_var_name, " & ", pollutant_var_name),
              subtitle=paste0("r = ", correlation,
                              ", p-value = ",round(t_test$p.value,4)))
}
```

```{r run plots, warning=F, message=F, echo=F}
# Blood Oxygen and Sulfur Dioxide
my_plot(health_var = blood_oxygen,
        health_var_name = "Blood Oxygen",
        health_var_units = "%",
        pollutant_var = sulfur_dioxide,
        pollutant_var_name = "Sulfur Dioxide",
        pollutant_var_units = "ppb")

# Heart Rate and Sulfur Dioxide
my_plot(health_var = heart_rate,
        health_var_name = "Heart Rate",
        health_var_units = "bpm",
        pollutant_var = sulfur_dioxide,
        pollutant_var_name = "Sulfur Dioxide",
        pollutant_var_units = "ppb")

# Heart Rate and Methane
my_plot(health_var = heart_rate,
        health_var_name = "Heart Rate",
        health_var_units = "bpm",
        pollutant_var = methane,
        pollutant_var_name = "Methane",
        pollutant_var_units = "ppb")
```

## Spatial Analysis

### Load shapefiles
```{r load Contra Costa County shapefile, message=F, warning=F}
# Loads pre-saved file from
# http://www.contracosta.ca.gov/4475/Maps-and-Data
# Projection: NAD 1983 StatePlane California III FIPS 0403 Feet
cc <- readOGR(dsn ="../refinery_data/location/BaseMapGrid", layer = "GRD_PWD_BaseMap_0106")
# summary(cc)

# Converts to longlat figure
cc_wgs84 <- spTransform(cc, CRS("+proj=longlat +datum=WGS84"))
# summary(cc_wgs84)
# coordinates(cc_wgs84)
# plot(cc_wgs84)

#plot of contra costa county
r <- ggplot(cc_wgs84, aes(x=long, y=lat)) +   
            geom_path(aes(group=group)) + coord_map("mercator")
r + 
  geom_point(data=spatial_df, aes(x=longitude, y=latitude, color = id), na.rm = T) + 
  geom_point(aes(x= refinery[1], y= refinery[2]))

r + 
  geom_point(data=spatial_df, aes(x=longitude, y=latitude, 
                                  color = heart_rate), na.rm = T) + 
  geom_point(aes(x= refinery[1], y= refinery[2])) 
```

### Spatial analysis
```{r spatial analysis, warning=F, message=F}
# autocorrelation - need a universe of points
# http://www.rspatial.org/analysis/rst/3-spauto.html#compute-moran-s-i
# for binary data, the join-count index
# https://cran.r-project.org/web/packages/spdep/spdep.pdf
# Find which points are near

points <- spatial_df %>% select(longitude, latitude)

spatial_df_t <- spatial_df %>% select(-c(longitude, latitude))

q <- SpatialPointsDataFrame(coords = points, 
                       data = spatial_df_t, 
                       proj4string = CRS("+proj=longlat +datum=WGS84"),
                       match.ID = T)

spat_points <- SpatialPoints(points,proj4string = CRS("+proj=longlat +datum=WGS84")) 
points_nb <- dnearneigh(spat_points, d1 = 0, d2 = .1)
class(points_nb)
summary(points_nb)
spatial_weights <- nb2mat(points_nb, zero.policy = T)
spatial_listw <- nb2listw(points_nb, zero.policy =T)

# Moran's I Monte Carlo
moran.mc(spatial_df$heart_rate, spatial_listw, nsim=99, zero.policy = T, na.action = na.omit)

# Converts to dataset for analysis
cc_data <- as.owin(cc_wgs84)
cc_ppp<-as.ppp(cc_data, W=cc_data) #turns dataset into point pattern


library(raster)
pointDistance(c(spatial_df$home_long, spatial_df$home_lat), lonlat = T) # distance matrix

# Kernel densities
burg2 <- density(burg, sigma=0.2)
burg2 <- density(burg, sigma=0.2)
plot(burg2, main= "Burglaries")
contour(burg2, add=T)

burg2 <- density(burg, sigma=0.5)
plot(burg2, main= "Burglaries")
contour(burg2, add=T)

#Select sigma (bandwidth) of .25 because actually shows 1st and 2nd order effects


##2. Point Pattern Analysis
#Pick 2: Narcotics and Disorderly Conduct
#2 methods each (quadrats, mean nearest neighbors, G, F, Ripley's K, PCF)
#Let's do Ripley's K and PCF

#Narcotics
par(mfrow=c(1,2))
dnarc <- density(narc, sigma=0.4)
env <- envelope(narc, pcf, simulate=expression(rpoispp(dnarc)), nsim=99) 
plot(env, ylim=c(0,8), main='Envelope for 99 simulations PCF, Narcotics')
plot(dnarc, main="Density of Narcotics, sigma=0.4")
plot(narc, add=TRUE)

par(mfrow=c(1,1))
dnarc <- density(narc, sigma=0.4)
env <- envelope(narc, Gest, simulate=expression(rpoispp(dnarc)), nsim=99) 
plot(env, ylim=c(0,1), main='Envelope for 99 simulations G fxn, Narcotics')
plot(dnarc, main="Density of Narcotics, sigma=0.4")
plot(narc, add=TRUE)

#Disorderly Conduct
par(mfrow=c(1,2))
dendc <- density(dc, sigma=0.4)
env <- envelope(dc, pcf, simulate=expression(rpoispp(dendc)), nsim=99) 
plot(env, ylim=c(0,8), main='Envelope for 99 simulations PCF, DC')
plot(dendc, main="Density of DC, sigma=0.4")
plot(dc, add=TRUE)

par(mfrow=c(1,1))
dendc <- density(dc, sigma=0.4)
env <- envelope(dc, Gest, simulate=expression(rpoispp(dendc)), nsim=99) 
plot(env, ylim=c(0,1), main='Envelope for 99 simulations G fxn, DC')
plot(dendc, main="Density of DC, sigma=0.4")
plot(dc, add=TRUE)

plot(Gest(dc), main= "G function DC") 
plot(Fest(dc), main= "F function DC") 
plot(Kest(dc), main= "K function DC") 
plot(pcf(dc), main= "PCF DC")

par(mfrow=c(1,1))
dendc <- density(dc, sigma=0.37)
env <- envelope(dc, Gest, simulate=expression(rpoispp(dendc)), nsim=99) 
plot(env, ylim=c(0,4), main='Envelope for 499 simulations PCF, DC')
plot(dendc, main="Density of DC, sigma=0.5")
plot(dc, add=TRUE)
```

### Load outside maps
```{r outside maps, include=F}
## Load community health assessment data
ces <- readOGR(dsn ="../refinery_data/location/CES3Results", layer = "CES3Results")
summary(ces)
ces_lat <- spTransform(ces, CRS("+proj=longlat +datum=WGS84"))
ces_lat_cc <- subset(ces_lat, County == "Contra Costa")
View(ces_lat_cc)
summary(ces_lat_cc)
plot(ces_lat_cc)

# http://mazamascience.com/WorkingWithData/?p=1494
# add to data a new column termed "id" composed of the rownames of data
ces_lat_cc@data$id <- rownames(ces_lat_cc@data)

# create a data.frame from our spatial object
new_data <- fortify(ces_lat_cc, region = "id")

# merge the "fortified" data with the data from our spatial object
waterDF <- merge(new_data, ces_lat_cc@data, by = "id")

# Map the cardiovascular instances
ggplot(waterDF, aes(x=long, y=lat, 
                    group = group, 
                    fill = Cardiovasc)) +
  geom_polygon()  +
  geom_path(color = "white") +
  scale_fill_gradient(
    low = "plum1", high = "purple4",
    breaks=c(500000,1000000,1500000),
    labels=c("Low","Medium","High")) +
  coord_map("mercator") + 
  ggtitle("Cardiovascular Health")
```

### Leaflet
```{r leaflet, warning=F, message=F, echo=F}
# https://rstudio.github.io/leaflet/

# generate map
map = leaflet(data = spatial_df) %>% 
  addTiles()
map %>% addCircleMarkers(
  lng = ~home_long,
  lat = ~home_lat,
  radius = 4,
  stroke = FALSE,
  color = "black",
  fillOpacity = 0.8,
  popup = paste0("<b>ID: </b>", "<b>",spatial_df$id,"</b>", "<br>",
                  "Age: ", spatial_df$age, "<br>",
                  "Sex: ", spatial_df$sex),
  popupOptions()) 

?addCircleMarkers
# Excess from Rich
#  addProviderTiles(providers$Esri.WorldTerrain)
#  addLegend("topright", pal = pal, # use custom palette
#            values = ~Result,
#            title = paste(d, t, sep = " "),
#            labFormat = labelFormat(suffix = " mg/L"),
#            opacity = 1
# setView(lng = lonCenter, lat = latCenter, zoom = 8)
```
