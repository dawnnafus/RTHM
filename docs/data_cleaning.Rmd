---
title: "Cleaning the Data"
output: 
  html_document:
   toc: true
---

```{r setup, include=FALSE, echo=F}
knitr::opts_chunk$set(echo = TRUE)
# List of R packages
required_pkg <- c("tidyverse","maptools", "rgdal", "spatstat", "ggmap", "geosphere", "leaflet", "spdep", "sp")
#pkgs_not_installed <- required_pkg[!sapply(required_pkg, function(p) require(p, character.only=T))]
#install.packages(pkgs_not_installed, dependencies=TRUE)

# Load all libraries at once.
lapply(required_pkg, library, character.only = TRUE) 
```

```{r time dataset, message=F, warning=F, echo=F}
# Inputs here are date_begin and date_end
begin = "2016-05-09 14:00"
end = "2016-08-11 0:00"

timeframe <- function(date_begin = begin, 
                      date_end = end){
  exp_begin = as.POSIXct(date_begin, tz="GMT", format="%Y-%m-%d %H")
  exp_end = as.POSIXct(date_end, tz="GMT", format="%Y-%m-%d %H")
  out = data_frame(day = seq(exp_begin, exp_end, by = 3600))
  return(out)
}
full_time <- timeframe()

exp_begin = as.POSIXct(begin, tz="GMT", format="%Y-%m-%d %H")
exp_end = as.POSIXct(end, tz="GMT", format="%Y-%m-%d %H")
```

```{r load air quality data, warning=F, message=F, echo=F}
# load air quality data
feed_4902 <- read_csv("../../refinery_data/airQuality_feed4902_data.csv"
                      #, skip =2
                      )
feed_4901 <- read_csv("../../refinery_data/airQuality_feed4901_data.csv"
                      #, skip =2
                      )
feed_4902_methane <- read_csv("../../refinery_data/airQuality_N20_methane_4902_data.csv"
                              #, skip =2
                              )

# Make hourly averages
## Set zero's to NA to not "mess up" average
feed_4902[feed_4902 == 0] <- NA
## Create new dataframe
hourly_4902 <- feed_4902 %>%
  # Select the day and hour of interest (get rid of minute and seconds)
  group_by(
    # Creates new variables
    day = as.POSIXct(cut(t, breaks='hour'))) %>%
  summarise(
    # Averages
    sulfur_dioxide = mean(sulfurDioxide, na.rm=T),
    carbon_monoxide = mean(carbonMonoxide, na.rm=T),
    ozone = mean(ozone, na.rm=T),
    pm_2.5 = mean(pm2_5, na.rm=T)
    ) %>%
  ungroup() %>%
  # Arrange the columns by day
  arrange(day) %>%
  full_join(full_time, by = "day")

# Do the same for the other feed 4902 dataframe
feed_4902_methane[feed_4902_methane == 0] <- NA
hourly_4902_methane <- feed_4902_methane %>%
    group_by(
    # Creates new variables
    day = as.POSIXct(cut(t, breaks='hour'))) %>%
  summarise(
    # Averages
    methane = mean(Methane, na.rm=T),
    benzene = mean(Benzene, na.rm=T),
    nitrous_oxide = mean(`Nitrous Oxide`, na.rm=T),
    xylene = mean(Xylene, na.rm=T)
    ) %>%
  # Arrange the columns by day
  arrange(day) %>%
  full_join(full_time, by = "day")

# Merge feed 4902 data
air_qual_4902 <- right_join(hourly_4902, hourly_4902_methane, by = "day") %>%
  mutate(id = "feed_4902")

# Do the same for feed 4901
feed_4901[feed_4901 == 0] <- NA
air_qual_4901 <- feed_4901 %>%
  # Select the day and hour of interest (get rid of minute and seconds)
  group_by(
    # Creates new variables
    day = as.POSIXct(cut(t, breaks='hour'))) %>%
    # Averages
  summarise(
    sulfur_dioxide = mean(sulfurDioxide, na.rm=T),
    carbon_monoxide = mean(carbonMonoxide, na.rm=T),
    ozone = mean(ozone, na.rm=T),
    pm_2.5 = mean(pm2_5, na.rm=T)
    ) %>%
  mutate(
    id = "feed_4901"
    ) %>%
  # Arrange the columns by day
  arrange(day) %>%
  full_join(full_time, by = "day")

# Remove intermediate dataframes
rm(hourly_4902, hourly_4902_methane)
# Remove original dataframes
rm(feed_4901, feed_4902, feed_4902_methane)
```

```{r create air quality dataset, message=F, warning=F, echo=F}
# Merge feeds
air_quality <- full_join(full_time, air_qual_4901, by = "day") %>%
  full_join(air_qual_4902, 
            by = c("day", "id", "sulfur_dioxide",
                   "carbon_monoxide", "ozone", "pm_2.5")) %>%
  select(day, id, everything()) %>%
  mutate(id = as.factor(id)) %>%
  arrange(day)

# Remove intermediate dataframes
rm(air_qual_4901, air_qual_4902)

# Collect refinery address from google
refinery = as.numeric(geocode("525 Castro St, Richmond, CA 94801", 
                              source = "google"))

# Add refinery coordinates to air quality
air_quality <- air_quality %>%
  mutate(
    longitude = refinery[1],
    latitude = refinery[2])
```

```{r exposure window, message=F, warning=F, echo=F}
# Moving window average of sulfur dioxide
air_quality <- 
  air_quality %>% 
  group_by(id) %>% 
  arrange(day) %>%
  mutate(
    sulfur_dioxide_exposure_window = 
      zoo::rollapply(sulfur_dioxide,
                     width = 8, #TO DO: Select number of hours to include
                     FUN = mean, #function is mean
                     na.rm = T, #avoids NA
                     partial = T, #skips unnecessary datapoints
                     align = "right")) %>%
  ungroup %>%
  arrange(id, day)
```

```{r load paco data, warning=F, message=F, echo=F}
# load paco data
paco <- read_csv("../../refinery_data/paco_all.csv")

# Creating new dataframe
paco <- paco %>%
  mutate(
    # Remove extra values (supposed to be a correction)
    when=gsub("\\+0000","",when),
    # Converting / to - part 1
    when=sub("[[:punct:]]","-",when),
    # Converting / to - part 2
    when=sub("\\/","-",when),
    # Rename persons of interest
    who = replace(who, who=="meaningfrommonitoring3@gmail.com", "m3"),
    who = replace(who, who=="meaningfrommonitoring5@gmail.com", "m5"),
    who = replace(who, who=="meaningfrommonitoring7@gmail.com", "m7"),
    who = replace(who, who=="meaningfrommonitoring9@gmail.com", "m9"),
    who = replace(who, who=="meaningfrommonitoring10@gmail.com", "m10"),
    who = replace(who, who=="meaningfrommonitoring11@gmail.com", "m11"),
    who = replace(who, who=="meaningfrommonitoring16@gmail.com", "m16")
  ) %>%
  mutate(
    # Make person column as a factor
    id = as.factor(who),
    # Convert date column to datetime
    t = as.POSIXct(when, tz="GMT", format="%Y-%m-%d %H:%M:%S")) %>%
  # Remove columns not of interest
  select(-c(who, when, appId, pacoVersion, experimentId,
            experimentName, experimentVersion, experimentGroupName,
            actionTriggerId, actionId, actionSpecId, responseTime,
            scheduledTime, timeZone)) %>%
  # Select persons of interest 
  filter(id == "m3" | id == "m5" | id == "m7" |
      id == "m9" | id == "m10" | id == "m11" |
      id == "m16") %>%
  arrange(t)

# Remove unlikely values
paco$SPO2[paco$SPO2 > 100 | paco$SPO2 < 80] <- NA

# Make hourly dataframe
paco_hourly <- paco %>%
  # Select the person, day and hour of interest
  group_by(id,
    # Creates new variables
    day = as.POSIXct(cut(t, breaks='hour'))) %>%
  # Average
  summarise(
    blood_oxygen = mean(SPO2, na.rm=T),
    symptoms = first(Symptoms),
    doctor = first(doctor),
    medicine = first(medicine),
    text_entry = first(`Participant choice`)
    ) %>%
  filter(is.na(blood_oxygen) == F) %>% 
  complete(nesting(id), 
           day = seq(exp_begin, exp_end, by = 3600),  
           #completing all levels of id:day
           fill = list(blood_oxygen = NA)) %>%
  ungroup %>%
  # Select persons of interest 
  filter(id == "m3" | id == "m5" | id == "m7" |
      id == "m9" | id == "m10" | id == "m11" |
      id == "m16") %>%
  # Arrange the columns by person
  arrange(id)

# Remove original dataframe
rm(paco)
```

```{r load fitbit data, message=F, warning=F, echo=F}
# Load intraday activity
fb_intraday_m3 <- read_csv("../../refinery_data/fitbit_intradayactivities_m3.csv"
                           #, skip =2
                           ) %>%
  mutate(id = "m3")
fb_intraday_m5 <- read_csv("../../refinery_data/fitbit_intradayactivities_m5.csv"
                           #, skip =2
                           )%>%
  mutate(id = "m5")
fb_intraday_m7 <- read_csv("../../refinery_data/fitbit_intradayactivities_m7.csv"
                           #, skip =2
                           )%>%
  mutate(id = "m7")
fb_intraday_m9 <- read_csv("../../refinery_data/fitbit_intradayactivities_m9.csv"
                           #, skip =2
                           )%>%
  mutate(id = "m9")
fb_intraday_m11 <- read_csv("../../refinery_data/fitbit_intradayactivities_m11.csv"
                            #, skip =2
                            )%>%
  mutate(id = "m11")
fb_intraday_m16 <- read_csv("../../refinery_data/fitbit_intradayactivities_m16.csv"
                            #, skip =2
                            )%>%
  mutate(id = "m16")

# Combine dataframes
fb_intra <- bind_rows(fb_intraday_m3, fb_intraday_m5, .id = NULL) %>%
  bind_rows(fb_intraday_m7, .id = NULL) %>%
  bind_rows(fb_intraday_m9, .id = NULL) %>%
  bind_rows(fb_intraday_m11, .id = NULL) %>%
  bind_rows(fb_intraday_m16, .id = NULL) %>%
  mutate(id = as.factor(id))

# Remove intermediate dataframes
rm(fb_intraday_m3, fb_intraday_m5, fb_intraday_m7,
   fb_intraday_m9, fb_intraday_m11, fb_intraday_m16)

# Make hourly data
fb_intraday <- fb_intra %>% 
  group_by(id,
    # Creates new variables
    day = as.POSIXct(cut(t, breaks='hour'))) %>%
  summarise(
    # Averages
    calories = sum(calories, na.rm=T),
    distance = sum(distance, na.rm=T),
    steps = sum(steps, na.rm=T),
    heart_rate = mean(heart, na.rm=T),
    floors = sum(floors, na.rm=T),
    elevation = sum(elevation, na.rm=T)) %>%
    complete(nesting(id),
             day = seq(exp_begin, exp_end, by = 3600),
             #completing all levels of id:day
             fill = list(calories = NA,distance = NA,
                         steps = NA, heart_rate = NA,
                         floors = NA, elevation = NA)) %>%
  # Select persons of interest 
  filter(id == "m3" | id == "m5" | id == "m7" |
      id == "m9" | id == "m10" | id == "m11" |
      id == "m16") %>%
  # Arrange the columns by day
  arrange(id, day) 

# Remove original dataframes
rm(fb_intra)
```

```{r make individual data, message=F, warning=F, echo=F}
# Collect participant home addresses
m3_home = as.numeric(
  geocode("460 3rd St, Richmond, CA 94801",
          source="google"))
m5_home = as.numeric(
  geocode("2515 Downer Ave, Richmond, CA 94804",
          source="google"))
m7_home = as.numeric(
  geocode("2640 Esmond Ave, Richmond, CA 94804",
          source="google"))
m9_home = as.numeric(
  geocode("1612 Mission Ave, San Pablo, CA 94806",
          source="google"))
m10_home = as.numeric(
  geocode("1832 4th St, Richmond, CA 94801",
          source="google"))
m11_home = as.numeric(
  geocode("2836 18th St, San Pablo, CA 94806",
          source="google"))
m16_home = as.numeric(
  geocode("5733 Oakmont Dr, Richmond, CA 94806",
          source="google"))

# Make demographics dataframe
# Will load in later
demographics <- data_frame(
  id =  c("m3","m5","m7","m9","m10","m11","m16"),
  age = c(21,34,45,33,56,67,51),
  time_in_area = c(20,16,5,10,50,32,27),
  home_lat = c(m3_home[2], m5_home[2], m7_home[2],
               m9_home[2], m10_home[2], m11_home[2], m16_home[2]),
  home_long = c(m3_home[1], m5_home[1], m7_home[1],
                m9_home[1], m10_home[1], m11_home[1], m16_home[1]),
  sex = as.factor(c("male","female","male","female","female","male","female"))) %>%
  mutate(
    home_dist_to_refinery = distm(cbind(home_long, home_lat), 
                                  refinery, 
                                  fun= distHaversine))

# LongLat randomizer
# Will have real GPS data loaded 
set.seed(0)
long_possible = (-12243009:-12153414)/100000
lat_possible = (3771863:3809988)/100000
longitude = sample(long_possible,24414, replace = T)
latitude = sample(lat_possible,24414, replace = T)

# Merge demographics with fitbit and paco datasets
fb_data <- left_join(fb_intraday, demographics, by = "id") %>%
  ungroup %>%
  mutate(id = as.factor(id))
paco_data <- full_join(paco_hourly, demographics, by = "id") %>%
  ungroup %>%
  mutate(id = as.factor(id))

# Combine all individual data
individual_data <- fb_data %>%
  bind_rows(paco_data, .id = NULL) %>%
  filter((heart_rate > 30 & heart_rate < 200) | is.na(heart_rate)) %>%
  mutate(
    longitude = sample(longitude, replace = T),
    latitude = sample(latitude, replace = T))

# Remove old dataframes
rm(paco_hourly, fb_intraday, paco_data, fb_data)
```

```{r export data, warning=F, message=F, echo=F}
write_csv(air_quality, path = "../../refinery_data/data/air_quality.csv")
write_csv(individual_data, path = "../../refinery_data/data/individual_data.csv")
```
